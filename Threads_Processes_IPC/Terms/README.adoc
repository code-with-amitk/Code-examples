:toc:
:toclevels: 6


== link:https://en.cppreference.com/w/cpp/atomic/atomic[Atomic]
* Atomic means something that cannot be broken down into smaller parts
* if one thread executes an atomic operation, it means that other thread will never see half-finished result.
* The end result of Atomic Operation is predictable and correct.
* If one thread writes to an atomic object while another thread reads from it, the behavior is well-defined. 
* This can used as Inter Process Synchronization. Example:
```cpp
a = 0;
void fun () {     //2 Threads executing this function
  a += 12;
}

=== Problem without Atomic
- Thread-1 enters fun() does a=12, At this point of execution, thread-1 is preempted and another thread-2 gets into same function.
- Thread-2 does a=12
- Thread-1 comes back and has previous value (12), instead of writing(24), it ends up in writing (12). But value should be 24.
  
=== Solution(Make operation a+=12 atomic):
a. Take a as volatile
b. Use synchronization methods.
```

=== Atomic Variables
- Used for shared-memory communication between threads these are safe to share between threads ie values at end in these variables in not vague/unpredictable after n threads finished operating.

==== C++
- std::atomic is neither copyable nor movable.
```cpp
#include <iostream>
#include <atomic>
#include <thread>

std::atomic_int var (0);        //Atomic Variable

void set(int x) {
  var.store (x, std::memory_order_relaxed);
}

void get() {
  int x;
  do {
    x = var.load(std::memory_order_relaxed);  // get value atomically
  } while (x==0);
  std::cout << "var: " << x << '\n';
}

int main () {
  std::thread t1 (get);
  std::thread t2 (set, 10);
  t1.join();
  t2.join();
}
$ g++ test.cpp -lpthread
$ ./a.out
var: 10
```

==== Rust 
```rs
let mut a_atm:AtomicU32 = Atomic:U32::new(100);          //Create and Initialize Atomic variable(a_atm)
let mut b_atm:AtomicU32 = Atomic:U32::new(5);

pub struct test {
    a: AtomicU64,
};
static TEST: Lazy<Arc<test>> = Lazy::new(|| Arc::new(test::new()))
impl test {
    pub fn increment_a_by(x: u64) {
        TEST.a.fetch_add(x, Ordering::Relaxed);
    }
    pub fn get_a() -> u64 {
        TEST.a.load(Ordering::Relaxed)
    }
};
fn main() {
  test::increment_a_by(1);
  println!("{}", test::get_a());
}
```

== Bound Waiting
Process-2 waits outside critical section while process-1 is executing inside.

== Busy Waiting
**spinlock is Busy waiting**
- Thread-1(or process-1) is in Critical section and has set atomic variable var=1, before entering into CS.
- Thread-2 keeps checking var continously in while(1) to be 0 and enter CS.

**Busy waiting when doing IO**
- Let's suppose UserSpace program wants to read IO device. It invokes [Device Driver using device file](/Device_Drivers/Linux).
- [Device driver writes to Device Controller's register](/Device_Drivers/Linux/#how) for reading memory address & device driver sits in loop, continuously polling the device to see if it is done 
- When IO is completed data(if any) is returned to driver. Device driver returns control to user space process. User space process was said to be in busy waiting.

== Concurrent (opposite of sequential)
Alternate between two tasks, then you are working on both tasks concurrently, but not in [parallelism](#pa)

== Conditional Variable / Condition Variable / shared variable
- This is used for synchronization.
- This block 1 thread/or multiple threads, until another thread modifies a shared variable (the condition), and notifies the condition_variable.
- Implemented as class in C++. [Code](/Threads_Processes_IPC/IPC/synchronization/Condition_Variable)

== Context Switch
- Means giving CPU from 1 process to other by scheduler.
- Each process is given a time interval(called its quantum) during which it is allowed to run. If the process keeps on running after the quantum also, CPU is preempted(fetched) from process and given to another process. 
- When the scheduler switches the CPU from executing process-1 to another process-2, the state of the current running process-1 is stored in its [Process Control Block](https://code-with-amitk.github.io/Motherboard/Memory/Processes.html#pcb). 

=== Tasks Done before CS
- **Suppose CS needed to be done from processA to processB**
  - _a._ Save processA registers, Remove Physical to Virtual Map (in MMU), Flush TLB for processA.
  - _b._ Load processB registers, Update Physical to Virtual Map (in MMU), Update TLB for processB.
- **Context switch from ProcessB to processA:** perform operations a and b again.
  - _c._ Additionally, Flushing memory caches(L1,L2,L3), reloading memory caches

=== Is context switch good? No(its wastage of CPU time). 
- _Smaller Quantum:_ Suppose quantum is of 4millisec, Context switch(saving loading registers, caches etc) is of 1millisec. 4 1 4 1 4 1 ... After 100millisec. 20millisec wasted in context switch(that's waste of CPU time).
- _Larger Quantum:_ Suppose quantum is of 100millisec, Context switch is 1millisec. 100 1 100 1. if 50 processes are in queue. last process will get CPU after 5 seconds. That's too long.
- _Reasonable Quantum:_ 20-50millisec

== Critical Section(requires Mutual Exclusion)
  - Piece of code where 2 processes/threads are not allowed to execute concurrently. 
  - Ex: shared data structures, peripheral device, or network connection. CS should be accessed using synchronization. Eg: semaphore
- **Pareto Principle** 90% of CPU cycles are spent in 10% of code. Means we have to focus & parallelly implement this 10% of code

== CPU Bound 
Process spends most of time with CPU executing instructions. From Source: Program doing lot of calculations Eg: finding all possible permutations of a string.

== Deadlock
2 or more threads waits on resources which is/are held by each other. None of thread releases the resource and in turn waits for other to release. 
```c
Example-1
  Thread-1 acquires mutex-a. 
  Thread-2 acquires mutex-b. 
  Thread-1 wants to acquire mutex-b, thread-2 mutex-a
- Example-2:    
  Thread-1 acquires mutex a, b.    
  Thread-2 acquires mutex b,a
  
//Code for creating Deadlock
#include<pthread.h>
pthread_mutex_t     a = PTHREAD_MUTEX_INITIALIZER;
pthread_mutex_t     b = PTHREAD_MUTEX_INITIALIZER;
void *thread-1(void *k){
    while(1){
        pthread_mutex_lock(&a); 
        pthread_mutex_lock(&b);
        pthread_mutex_unlock(&b);
        pthread_mutex_unlock(&a);
    }
}

void *thread-2(void *k){
    while(1){
        pthread_mutex_lock(&b); 
        pthread_mutex_lock(&a);
        pthread_mutex_unlock(&a);
        pthread_mutex_unlock(&b);
    }
}
main(){
  pthread_t tid1;
  pthread_t tid2;
  pthread_create(&tid1, NULL, thread1, NULL);
  pthread_create(&tid2, NULL, thread2, NULL);
  pthread_join(tid1, NULL);     //Wait until thread-1 to terminate
  pthread_join(tid2, NULL);    ////Wait until thread-2 to terminate
}
```
**Using [lock_guard]()**
```cpp
//f1(), f2() created on process stack
//Thread1 f1()
  - takes lock_guard=mutex(lg1)
  - sleeps for 10ms
//Thread2 f2()
  - takes lock_guard=mutex(lg2)
//Thread1 f1()
  - Want lock_guard=mutex(lg1) which is already taken by Thread2  //Deadlock

#include<iostream>
#include<thread>
#include<mutex>
using namespace std;

std::mutex m1;
std::mutex m2;

void f1(){
        std::lock_guard<std::mutex> lg1(m1);
        std::this_thread::sleep_for(std::chrono::milliseconds(10));
        std::lock_guard<std::mutex> lg2(m2);
};

void f2() {
        std::lock_guard<std::mutex> lg1(m2);
        std::this_thread::sleep_for(std::chrono::milliseconds(10));
        std::lock_guard<std::mutex> lg2(m1);    //What if this statement is commeted, Will it Deadlock? Ans:No
};

int main() {
        thread t1(f1);
        thread t2(f2);
        t1.join();
        t2.join();
        cout << "exiting";
}
```

=== IO Bound 
Process spends most of time in IO. From source: Program doing lot of File RW operations.
```c
Q: Find whether a process is IO Bound or CPU Bound?
 top command has %cpu column(Total CPU time used by process from when its started). CPU bound will have high %cpu.
 while (i<100){    ++i;                //Its %cpu = 100
    if(i==98)
        i=0;
 }
 ```

== Parallelism
2 tasks assigned to 2 threads running on different cores.


== Race Condition
2 or more threads/processes are accessing/writing same shared resource(file, global variables etc) then at end result is unpredictable or wrong.

== Reentrant
  - Making second call same function while a previous call has not yet finished.
  - *Example:*
    - Suppose 2 threads can excute same function `fun()`.
    - Thread-1 executing is on line-11(writing to some big memory area `*ptr=bb`) of `fun()` & CPU decides to context switch. State of memory `*ptr` will be inconsistent and control is given to thread-2.
    - Thread-2 starts executing and writes to `*ptr=bbaaaa` and again context switch is done to thread-1.
    - Thread-1 comes back, expects `*ptr=bb` and starts writing `*ptr=bbbbb` and done.
    - Thread-2 reads `*ptr` thinking output as `bbaaaa` But `*ptr` is in inconsistent state.
  - **Solution:** mutex(But it eliminates parallelism)
```c
  fun(){            
      ...
11:    writing_to_big_memory (*ptr)
      ...
  }
  
int main(){  
  thread t1(fun);
  thread t2(fun);
  t1.join();
  t2.join();
}  
```

== Spurious wakeup. Spurious means Fake/False
- It means Thread waking up unneccessrily. A spurious wakeup happens when a thread wakes up from waiting on a condition variable that's been signaled, & it discovers that the condition it was waiting for isn't satisfied.
- It's called spurious because the thread has seemingly been awakened for no reason.
- **How Spurious Wakup happens?**
  - Thread waiting on condition, condition met, thread is signalled. Between thread going inside function another thread changes the conditional variable and waken up thread finds condition is not satified. This happens on Race condition.
- **How to avoid Spurious wakeup?**
  - One way to avoid this is using busy waiting.
```c
bool check = false;
condition_variable cv;
mutex m;
fun1 () {
  m.lock();  
  // Execute
  check = true;
  m.unlock();
}
fun2 () {
  m.lock();  
  /*if (check == false)             //This can lead to spurious wakeup
    return;*/
    
  while (check == false);          //Busy wait, avoids spurious wakeup
  
  // Execute
  m.unlock();
}

int main () {
  thread t1(fun1);    //OS can schedule any thread 1st
  thread t2(fun2);
}
```
